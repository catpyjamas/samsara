{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2aaf15-9aa9-4cce-aa44-f70c7339ba89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openaiNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached openai-1.90.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\tusaa\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.90.0-py3-none-any.whl (734 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl (206 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "Successfully installed jiter-0.10.0 openai-1.90.0\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69f9e6be-d7bd-4d6c-9cf8-74dd210a1c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing: https://thumbs.dreamstime.com/b/garbage-truck-accident-1807778.jpg?w=576\n",
      "Raw GPT output:\n",
      "{\"description\":\"Garbage truck with back door open, large amount of trash including bags and loose waste spilled onto street, minor liquid leakage, not obstructing traffic.\",\"severity\":7}\n",
      "\n",
      "\n",
      "=== Processing: https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTEJUtZWg5zh1-hzdpg7OSXXVFXujEcAlAqog&s\n",
      "Raw GPT output:\n",
      "{\"description\": \"A few pieces of paper have fallen next to trash bins, no significant spillage.\", \"severity\": 2}\n",
      "\n",
      "\n",
      "=== Processing: https://www.north-herts.gov.uk/sites/default/files/styles/3_2_landscape_795x530/public/2022-09/waste-purple-collection1500x1000.jpg?itok=Qr8vHi85\n",
      "Raw GPT output:\n",
      "{ \"description\": \"No visible spillage; garbage is contained within a bin being loaded into a truck.\", \"severity\": 1 }\n",
      "\n",
      "\n",
      "=== Processing: https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT4y7j6krEVagxqfbd3bB6nSl9GB48fkBT3_w&s\n",
      "Raw GPT output:\n",
      "{ \"description\": \"Garbage truck with trash spilling onto the street, covering a significant portion of the road.\", \"severity\": 7 }\n",
      "\n",
      "\n",
      "=== Processing: https://www.theargus.co.uk/resources/images/19313139/?type=responsive-gallery-fullscreen\n",
      "Raw GPT output:\n",
      "{ \"description\": \"Overflowing dumpsters with trash scattered around them, some waste spilling onto the street.\", \"severity\": 7 }\n",
      "\n",
      "\n",
      "✅ CSV created: image_descriptions.csv\n"
     ]
    }
   ],
   "source": [
    "# this is an example of how we can use a LLM with vision capabilities to scan through selected webcam footage for incidents related to spillage during waste collection\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "# ✅ Set API key\n",
    "os.environ[\"OPENAI_API_KEY\"] =\"MYKEY\"\n",
    "client = OpenAI()\n",
    "\n",
    "# ✅ Image URLs (in real life, we'd have processed 1000s of clips from driver footage; they'd be compressed down and in a folder)\n",
    "image_urls = [\n",
    "    \"https://thumbs.dreamstime.com/b/garbage-truck-accident-1807778.jpg?w=576\",\n",
    "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTEJUtZWg5zh1-hzdpg7OSXXVFXujEcAlAqog&s\",\n",
    "    \"https://www.north-herts.gov.uk/sites/default/files/styles/3_2_landscape_795x530/public/2022-09/waste-purple-collection1500x1000.jpg?itok=Qr8vHi85\",\n",
    "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT4y7j6krEVagxqfbd3bB6nSl9GB48fkBT3_w&s\",\n",
    "    \"https://www.theargus.co.uk/resources/images/19313139/?type=responsive-gallery-fullscreen\",\n",
    "]\n",
    "\n",
    "\n",
    "# ✅ Create CSV to record the results (later, we can use the images to train our models)\n",
    "with open(\"image_descriptions.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"image_url\", \"description\", \"severity_score\"])\n",
    "\n",
    "    for img_url in image_urls:\n",
    "        print(f\"\\n=== Processing: {img_url}\")\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a precise waste event scorer. Always follow instructions exactly.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": (\n",
    "                                # note on the prompt: I originally had a more generic prompt which gave severity score =7 for all images by being more descriptive and forcing chatgpt to forget previous images in this session, I got better results \n",
    "                                \"You are a waste management expert. I want you to describe any visible spillage (if existing) \"\n",
    "                                \"and give a numeric severity score from 1 (almost no mess) to 10 (extreme blockage).\\n\\n\"\n",
    "                                \"Calibration examples:\\n\"\n",
    "                                \"Example 1:\\n\"\n",
    "                                \"Description: A single small piece of trash on the curb.\\n\"\n",
    "                                \"Severity: 1\\n\\n\"\n",
    "                                \"Example 2:\\n\"\n",
    "                                \"Description: Large pile of garbage bags ripped open, trash scattered, blocking traffic.\\n\"\n",
    "                                \"Severity: 10\\n\\n\"\n",
    "                                \"Now, for THIS IMAGE ONLY, reply ONLY in JSON:\\n\"\n",
    "                                \"{ \\\"description\\\": \\\"<your description>\\\", \\\"severity\\\": <1-10> }\\n\"\n",
    "                                \"NO extra text. NO code block.\"\n",
    "                            )\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\"url\": img_url}\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        raw = response.choices[0].message.content.strip()\n",
    "        print(f\"Raw GPT output:\\n{raw}\\n\")\n",
    "\n",
    "        # ✅ Extract JSON\n",
    "        json_match = re.search(r\"\\{[\\s\\S]*\\}\", raw)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(0)\n",
    "            try:\n",
    "                data = json.loads(json_str)\n",
    "                description = data.get(\"description\", \"\")\n",
    "                severity = data.get(\"severity\", \"\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ JSON parsing failed: {json_str}\")\n",
    "                description = \"\"\n",
    "                severity = \"\"\n",
    "        else:\n",
    "            print(f\"❌ No JSON found in output: {raw}\")\n",
    "            description = \"\"\n",
    "            severity = \"\"\n",
    "\n",
    "        writer.writerow([img_url, description, severity])\n",
    "\n",
    "print(\"\\n✅ CSV created: image_descriptions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
